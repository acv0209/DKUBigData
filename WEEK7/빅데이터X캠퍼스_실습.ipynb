{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "빅데이터X캠퍼스 실습.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r0a8_GPdjUHu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **1. Numpy를 이용하여 Multi-Layer Perceptron 구현하기**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w0pCebdJbu1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "eaddaf2f-87ee-443e-9712-80553d4245c3"
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "epochs = 3000  \n",
        "inputLayerSize, hiddenLayerSize, outputLayerSize = 2, 3, 1\n",
        "# 인공적으로 랜덤 입력과 출력 만들기 x : 입력 y : 출력\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "# sigmoid와 그 미분을 함수로 선언\n",
        "def sigmoid(x): return 1 / (1 + np.exp(-x)) \n",
        "def sigmoid_derivative(x): return x * (1 - x)  \n",
        "\n",
        "\n",
        "\n",
        "Wh = np.random.uniform(size=(inputLayerSize, hiddenLayerSize))\n",
        "Wz = np.random.uniform(size=(hiddenLayerSize, outputLayerSize))\n",
        "for i in range(epochs):\n",
        "    H = sigmoid(np.dot(X, Wh)) # layer 1\n",
        "    Z = sigmoid(np.dot(H, Wz)) # layer 2  \n",
        "    E = np.square(Y - Z).sum() # error\n",
        "   \n",
        "    # back propagation\n",
        "    # w 갱신 = 기존 W - 출발노드의 output * 도착 노드의 delta\n",
        "    \n",
        "    dZ = (Y - Z) * sigmoid_derivative(Z)   # delta layer 2(output layer) : E에 대한 layer output 미분(Y-Z) * 활성화 함수 미분\n",
        "    dH = dZ.dot(Wz.T) * sigmoid_derivative(H)   # delta layer 1 : E에 대한 layer output 미분(delta layer 2*weight) * 활성화 함수 미분\n",
        "    \n",
        "    \n",
        "    Wz += H.T.dot(dZ) #Wz = Wz + H.T.dot(dz)\n",
        "    Wh += X.T.dot(dH)  \n",
        "\n",
        "print(Z)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.06083394]\n",
            " [0.96210347]\n",
            " [0.96210501]\n",
            " [0.0164211 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Q94XjYwD6RB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Keras를 이용하여 같은 Multi-Layer Perceptron 구현하기\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "코드가 매우 단순해지는 것을 볼 수 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "S1v6qjcQASiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "sgd = SGD(lr=0.1)\n",
        "\n",
        "epochs = 5000\n",
        "inputLayerSize, hiddenLayerSize, outputLayerSize = 2, 3, 1\n",
        "# 인공적으로 랜덤 입력과 출력 만들기 x : 입력 y : 출력\n",
        "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(hiddenLayerSize, input_dim=inputLayerSize, activation='sigmoid'))\n",
        "model.add(Dense(outputLayerSize, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy']) \n",
        "\n",
        "model.fit(x, y, batch_size=4, epochs=epochs)\n",
        "\n",
        "print(model.predict_proba(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UXuzDSCQGwzb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Keras를 이용하여 MNIST Classifier 구현하기\n",
        "\n",
        "---\n",
        "## MNIST 로딩하기\n",
        "\n",
        "MNIST같은 유명한 dataset은 따로 다운받지 않아도 Keras나 Tensorflow, Pytorch 등의 라이브러리에서 기본적으로 제공해주는 경우가 많습니다."
      ]
    },
    {
      "metadata": {
        "id": "0Plh26hPGwP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "\n",
        "nb_classes = 10 # class의 개수\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
        "# MNIST data 로딩. x: 이미지데이터  y: 이미지의 class\n",
        "print(\"X_train original shape\", X_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Yg2J30ZJBP0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 로딩된 데이터 확인해보기"
      ]
    },
    {
      "metadata": {
        "id": "-g-bXbMhHDYn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 시각화할 figure의 크기를 키운다(28*28이 실제 눈으로 보기에 좀 작기 때문)\n",
        "plt.rcParams['figure.figsize'] = (7,7)\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Class {}\".format(y_train[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JlPqfoNHqN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "metadata": {
        "id": "p3shyFrQHKW_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 벡터화. CNN을 사용하지 않을 것이기 때문에 28*28 이미지른 784차원 벡터로 vectorize한다.\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "# 정규화. 데이터의 범위를 0~255에서 0~1로 바꾼다.\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)\n",
        "\n",
        "# classification을 하기 위해 label을 categrical 형태로 변환.\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KdSuhaUHIorG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##모델 설계"
      ]
    },
    {
      "metadata": {
        "id": "UKcb5arKHfjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation('relu')) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vy3vBfqZIwGo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ]
    },
    {
      "metadata": {
        "id": "q2vY9vk7Iyn-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=4, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F50mA_pyJSwv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 학습 평가"
      ]
    },
    {
      "metadata": {
        "id": "I9BCgbTmIJoK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score)\n",
        "\n",
        "\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[i].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[i], y_test[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i04UdbnyJjeF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Keras를 이용하여 MNIST AutoEncoder 구현하기\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "Xs25TAPhMS9m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) \n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "#Encoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "#Decoder\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FE0J3Gyq2hJ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **결과 visualization**"
      ]
    },
    {
      "metadata": {
        "id": "pe_j8KGZ0HTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# visualize trained autoencoder\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}